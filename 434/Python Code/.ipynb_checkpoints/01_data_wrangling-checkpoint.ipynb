{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f036e0de-0ac8-4d4e-a4c9-34137913144d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'talib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtalib\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'talib'"
     ]
    }
   ],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import pandas_datareader as web\n",
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics as st\n",
    "from scipy.stats import mstats\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from statsmodels.formula.api import ols\n",
    "import pingouin as pg\n",
    "import schedule\n",
    "import time\n",
    "import requests\n",
    "import talib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5805ae69-a793-437d-934f-6d9f6d7bcc4d",
   "metadata": {},
   "source": [
    "### Collect Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001a420b-79d4-4d53-a064-930c0ff17bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_historical_data(ticker, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Collect historical stock data for a given ticker and time range.\n",
    "\n",
    "    Parameters:\n",
    "        ticker (str): Stock ticker symbol (e.g., 'AAPL')\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Historical stock data\n",
    "    \"\"\"\n",
    "    # Fetch the stock data from Yahoo Finance\n",
    "    yf.pdr_override()\n",
    "    stock_data = pdr.get_data_yahoo(ticker, start=start_date, end=end_date)\n",
    "    stock_data = stock_data.reset_index()\n",
    "\n",
    "    # Return the data\n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd223b9-9102-4ace-819b-2d42b5a53c3a",
   "metadata": {},
   "source": [
    "### Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf98754-6bad-46e6-9695-12c176a30440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_historical_data(stock_data):\n",
    "    \"\"\"\n",
    "    Clean the stock data by handling missing values, outliers, and standardizing formats.\n",
    "\n",
    "    Parameters:\n",
    "        stock_data (pd.DataFrame): Historical stock data to clean\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned stock data\n",
    "    \"\"\"\n",
    "    # Step 1: Handle Missing Values\n",
    "    # Forward fill or backward fill missing data\n",
    "    stock_data.fillna(method='ffill', inplace=True)\n",
    "    stock_data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "    # Step 2: Handle Outliers (Optional)\n",
    "    # Define thresholds for outliers (for example, extreme price fluctuations)\n",
    "    # You can set a threshold based on z-scores or percentage changes between rows.\n",
    "    z_scores = (stock_data['Close'] - stock_data['Close'].mean()) / stock_data['Close'].std()\n",
    "    \n",
    "    # Removing outliers with z-scores greater than 3 or less than -3 (adjust based on your strategy)\n",
    "    stock_data = stock_data[(np.abs(z_scores) < 3)]\n",
    "\n",
    "    # Step 3: Standardize Date/Time Format\n",
    "    # Ensure the index is in the correct datetime format\n",
    "    stock_data.index = pd.to_datetime(stock_data.index)\n",
    "\n",
    "    # Step 4: Drop duplicates if any (ensure no duplicated dates)\n",
    "    stock_data = stock_data.loc[~stock_data.index.duplicated(keep='first')]\n",
    "\n",
    "    print(\"Data after cleaning:\\n\", stock_data.head())\n",
    "    \n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee25a252-afe8-4f5d-8d09-0b447a224b6d",
   "metadata": {},
   "source": [
    "### Compute Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eed4a0b6-c0a9-4b45-822f-42e84977b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_technical_indicators(stock_data):\n",
    "    \"\"\"\n",
    "    Inspect and analyze the stock data by visualizing price trends and computing technical indicators.\n",
    "\n",
    "    Parameters:\n",
    "        stock_data (pd.DataFrame): Historical stock data to inspect and analyze\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate SMAs\n",
    "    stock_data['MA50'] = stock_data['Close'].rolling(window=50).mean()\n",
    "    stock_data['MA200'] = stock_data['Close'].rolling(window=200).mean()\n",
    "    \n",
    "    # Step 2: Calculate and Plot Moving Averages (MA)\n",
    "    stock_data['EMA20'] = talib.EMA(stock_data['Close'], timeperiod=20)\n",
    "    stock_data['EMA50'] = talib.EMA(stock_data['Close'], timeperiod=50)\n",
    "    \n",
    "    # Step 3: Calculate and Plot Bollinger Bands (Volatility)\n",
    "    stock_data['BB_upper'], stock_data['BB_middle'], stock_data['BB_lower'] = talib.BBANDS(\n",
    "        stock_data['Close'], timeperiod=20, nbdevup=2, nbdevdn=2)\n",
    "    \n",
    "    # Step 4: Calculate and Plot Relative Strength Index (RSI)\n",
    "    stock_data['RSI'] = talib.RSI(stock_data['Close'], timeperiod=14)\n",
    "    \n",
    "    # Add Stochastic Oscillator\n",
    "    stock_data['slowk'], stock_data['slowd'] = talib.STOCH(\n",
    "    stock_data['High'], stock_data['Low'], stock_data['Close'], fastk_period=14, slowk_period=3, slowd_period=3)\n",
    "\n",
    "    # Step 5: Calculate and Plot Moving Average Convergence Divergence (MACD)\n",
    "    macd, macdsignal, macdhist = talib.MACD(stock_data['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "    stock_data['MACD_Hist'] = macdhist\n",
    "    \n",
    "    # ATR\n",
    "    stock_data['ATR'] = talib.ATR(stock_data['High'], stock_data['Low'], stock_data['Close'], timeperiod=14)\n",
    "\n",
    "    # ADX\n",
    "    stock_data['ADX'] = talib.ADX(stock_data['High'], stock_data['Low'], stock_data['Close'], timeperiod=14)\n",
    "\n",
    "    # OBV (On-Balance Volume)\n",
    "    stock_data['OBV'] = talib.OBV(stock_data['Close'], stock_data['Volume'])\n",
    "\n",
    "    # Chaikin Money Flow (CMF)\n",
    "    stock_data['CMF'] = ((stock_data['Close'] - stock_data['Low']) - (stock_data['High'] - stock_data['Close'])) / (stock_data['High'] - stock_data['Low']) * stock_data['Volume']\n",
    "    stock_data['CMF'] = stock_data['CMF'].rolling(window=20).mean()\n",
    "    \n",
    "    # Step 6: Inspect basic statistics\n",
    "    return stock_data\n",
    "    #print(\"Basic Statistics of Stock Data:\\n\", stock_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee92912d-c671-47af-995c-54ccc91cebeb",
   "metadata": {},
   "source": [
    "### Collect Fundamental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dfee7c7-d4c6-4a78-91cc-f48a80fb39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fundamental_data(ticker):\n",
    "    \"\"\"\n",
    "    Fetch the most recent fundamental data for the ticker (e.g., quarterly updates).\n",
    "    \"\"\"\n",
    "    stock = yf.Ticker(ticker)\n",
    "    fundamentals = stock.info\n",
    "    \n",
    "    fundamental_data = {\n",
    "        'P/E Ratio': fundamentals.get('trailingPE'),\n",
    "        'EPS': fundamentals.get('trailingEps'),\n",
    "        'Dividend Yield': fundamentals.get('dividendYield'),\n",
    "        'Price-to-Book': fundamentals.get('priceToBook'),\n",
    "        'Market Cap': fundamentals.get('marketCap'),\n",
    "        'Revenue': fundamentals.get('totalRevenue'),\n",
    "        'Net Income': fundamentals.get('netIncomeToCommon')\n",
    "    }\n",
    "    return fundamental_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f9c6a9-3d37-4fd7-8e05-cea68d6ef641",
   "metadata": {},
   "source": [
    "### Fuse Historical and Fundamental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "383143bd-faec-488c-948a-9d39aa646ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_price_and_fundamental_data(stock_data, fundamental_data):\n",
    "    \"\"\"\n",
    "    Add fundamental data to the daily price data DataFrame, so every row has the same fundamental values.\n",
    "    \"\"\"\n",
    "    # Convert the fundamental data dictionary into a DataFrame with the same index as the price data\n",
    "    fundamentals_df = pd.DataFrame([fundamental_data] * len(stock_data), index=stock_data.index)\n",
    "    \n",
    "    # Concatenate the price data and fundamental data\n",
    "    fused_data = pd.concat([stock_data, fundamentals_df], axis=1)\n",
    "    \n",
    "    return fused_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d09c4-e4fe-4542-a7b8-16f35c5037ee",
   "metadata": {},
   "source": [
    "### Collect Macro Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3de49b9d-8fcc-434f-b612-1f4a27fefc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fred_data(series_id, api_key):\n",
    "    \"\"\"\n",
    "    Fetch macroeconomic data from FRED.\n",
    "    \"\"\"\n",
    "    url = f'https://api.stlouisfed.org/fred/series/observations?series_id={series_id}&api_key={api_key}&file_type=json'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()['observations']\n",
    "    df = pd.DataFrame(data)\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.set_index('date', inplace=True)\n",
    "    df['value'] = pd.to_numeric(df['value'])\n",
    "    return df\n",
    "\n",
    "def get_vix_data(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch VIX (Volatility Index) data from Yahoo Finance.\n",
    "    \"\"\"\n",
    "    vix_data = yf.download('^VIX', start=start_date, end=end_date)\n",
    "    return vix_data\n",
    "\n",
    "def get_oil_prices_data(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch WTI Crude Oil Prices from Yahoo Finance.\n",
    "    \"\"\"\n",
    "    oil_data = yf.download('CL=F', start=start_date, end=end_date)\n",
    "    return oil_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85f49753-1b44-4794-97ab-f0a48cee7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fill_macro_data(macro_data):\n",
    "    \"\"\"\n",
    "    Forward-fill macroeconomic data for daily alignment.\n",
    "    \"\"\"\n",
    "    return macro_data.reindex(pd.date_range(macro_data.index.min(), macro_data.index.max(), freq='D')).ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd82fcc4-4a8f-42e3-a3c2-67151397a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_macro_with_stock(fused_data, macro_data, column_name):\n",
    "    \"\"\"\n",
    "    Merge a single macroeconomic dataset with the stock data.\n",
    "    \n",
    "    Parameters:\n",
    "        fused_data (pd.DataFrame): The historical stock and fundamental dataset.\n",
    "        macro_data (pd.DataFrame): The macroeconomic data to merge.\n",
    "        column_name (str): Name for the new column in the merged dataset.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Fused dataset with the macroeconomic data added.\n",
    "    \"\"\"\n",
    "    # Ensure macro data has the correct column name for merging\n",
    "    macro_data = macro_data.rename(columns={'value': column_name})\n",
    "    \n",
    "    # Merge macro data with stock data on the index (date)\n",
    "    merged_data = pd.merge(fused_data, macro_data[[column_name]], how='left', left_index=True, right_index=True)\n",
    "    \n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e79222-e50d-484e-8c74-1d4a86d23db1",
   "metadata": {},
   "source": [
    "### Calculate Z-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9181e376-2e15-4d56-894d-f4fe24c9db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_z_score(df, window=20):\n",
    "    \"\"\"\n",
    "    Calculate the Z-Score of the closing price over a given rolling window.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing stock price data.\n",
    "        window (int): Rolling window size (e.g., 20 days).\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: Z-Scores of the closing price.\n",
    "    \"\"\"\n",
    "    rolling_mean = df['Close'].rolling(window=window).mean()\n",
    "    rolling_std = df['Close'].rolling(window=window).std()\n",
    "    \n",
    "    z_score = (df['Close'] - rolling_mean) / rolling_std\n",
    "    \n",
    "    return z_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485d9499-f059-4a6b-bca0-4d998fc7b032",
   "metadata": {},
   "source": [
    "### Calculate Fibonacci Retracement Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f29cc02c-ea17-4ba9-96b8-d4c5dab12253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fibonacci_levels(df, window=100):\n",
    "    \"\"\"\n",
    "    Calculate Fibonacci retracement levels based on the high and low points over a rolling window.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing stock price data.\n",
    "        window (int): Rolling window size (e.g., 100 days).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with Fibonacci levels (23.6%, 38.2%, 50%, 61.8%, 100%) for each day.\n",
    "    \"\"\"\n",
    "    high = df['High'].rolling(window=window).max()\n",
    "    low = df['Low'].rolling(window=window).min()\n",
    "    \n",
    "    # Fibonacci retracement levels\n",
    "    fib_236 = high - 0.236 * (high - low)\n",
    "    fib_382 = high - 0.382 * (high - low)\n",
    "    fib_50 = high - 0.5 * (high - low)\n",
    "    fib_618 = high - 0.618 * (high - low)\n",
    "    fib_100 = high\n",
    "    \n",
    "    fib_df = pd.DataFrame({\n",
    "        'Fib_23.6%': fib_236,\n",
    "        'Fib_38.2%': fib_382,\n",
    "        'Fib_50%': fib_50,\n",
    "        'Fib_61.8%': fib_618,\n",
    "        'Fib_100%': fib_100\n",
    "    }, index=df.index)\n",
    "    \n",
    "    return fib_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543c6640-64b5-4d39-aea6-16213b48e6ec",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c15d687-2945-4af6-8964-abe428cd13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_stock_data(stock_data, ticker):\n",
    "    \"\"\"\n",
    "    Save the stock data to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "        stock_data (pd.DataFrame): Historical stock data\n",
    "        ticker (str): Stock ticker symbol to use in the filename\n",
    "    \"\"\"\n",
    "    # Save to CSV\n",
    "    file_name = f\"Data/{ticker}_merged_data.csv\"\n",
    "    stock_data.to_csv(file_name)\n",
    "    print(f\"Data saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672d3b1a-dc45-4a63-af7e-4a83542555e6",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "431f3bb1-a400-49be-9acd-1fd5cfe6885b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aless\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\yfinance\\utils.py:775: FutureWarning: The 'unit' keyword in TimedeltaIndex construction is deprecated and will be removed in a future version. Use pd.to_timedelta instead.\n",
      "  df.index += _pd.TimedeltaIndex(dst_error_hours, 'h')\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "C:\\Users\\aless\\AppData\\Local\\Temp\\ipykernel_28828\\501115791.py:13: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  stock_data.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\aless\\AppData\\Local\\Temp\\ipykernel_28828\\501115791.py:14: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  stock_data.fillna(method='bfill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning:\n",
      "                                     Date       Open       High        Low  \\\n",
      "1970-01-01 00:00:00.000000000 2013-01-02  19.779285  19.821428  19.343929   \n",
      "1970-01-01 00:00:00.000000001 2013-01-03  19.567142  19.631071  19.321428   \n",
      "1970-01-01 00:00:00.000000002 2013-01-04  19.177500  19.236786  18.779642   \n",
      "1970-01-01 00:00:00.000000003 2013-01-07  18.642857  18.903570  18.400000   \n",
      "1970-01-01 00:00:00.000000004 2013-01-08  18.900356  18.996071  18.616072   \n",
      "\n",
      "                                   Close  Adj Close     Volume  \n",
      "1970-01-01 00:00:00.000000000  19.608213  16.705706  560518000  \n",
      "1970-01-01 00:00:00.000000001  19.360714  16.494837  352965200  \n",
      "1970-01-01 00:00:00.000000002  18.821428  16.035385  594333600  \n",
      "1970-01-01 00:00:00.000000003  18.710714  15.941053  484156400  \n",
      "1970-01-01 00:00:00.000000004  18.761070  15.983951  458707200  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'talib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 69\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Run the main function\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 15\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m clean_historical_data(stock_data)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Step 4: Compute technical indicators\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mcompute_technical_indicators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstock_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Step 5: Collect fundamental data\u001b[39;00m\n\u001b[0;32m     18\u001b[0m fundamental_data \u001b[38;5;241m=\u001b[39m get_fundamental_data(ticker)\n",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m, in \u001b[0;36mcompute_technical_indicators\u001b[1;34m(stock_data)\u001b[0m\n\u001b[0;32m     11\u001b[0m stock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMA200\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m stock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mrolling(window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Step 2: Calculate and Plot Moving Averages (MA)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m stock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEMA20\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtalib\u001b[49m\u001b[38;5;241m.\u001b[39mEMA(stock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m], timeperiod\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m     15\u001b[0m stock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEMA50\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m talib\u001b[38;5;241m.\u001b[39mEMA(stock_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m], timeperiod\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Step 3: Calculate and Plot Bollinger Bands (Volatility)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'talib' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Parameters for data collection\n",
    "    ticker = 'AAPL'  # Apple Inc.\n",
    "    start_date = '2013-01-01'  # Start date (5 years of data)\n",
    "    end_date = '2023-01-01'    # End date\n",
    "    api_key = 'your_fred_api_key'\n",
    "\n",
    "    # Step 2: Collect stock data\n",
    "    stock_data = collect_historical_data(ticker, start_date, end_date)\n",
    "\n",
    "    # Step 3: Clean price data\n",
    "    clean_historical_data(stock_data)\n",
    "\n",
    "    # Step 4: Compute technical indicators\n",
    "    compute_technical_indicators(stock_data)\n",
    "\n",
    "    # Step 5: Collect fundamental data\n",
    "    fundamental_data = get_fundamental_data(ticker)\n",
    "\n",
    "    # Step 6: Fuse price and fundamental data\n",
    "    fused_data = fuse_price_and_fundamental_data(stock_data, fundamental_data)\n",
    "\n",
    "    # Step 7: Collect interest data\n",
    "    treasury_yield_df = get_fred_data('DGS10', api_key)\n",
    "\n",
    "    # Step 8: Collect inflation data\n",
    "    inflation_rate_df = get_fred_data('CPIAUCSL', api_key)\n",
    "\n",
    "    # Step 9: Collect unemployment data\n",
    "    unemployment_rate_df = get_fred_data('UNRATE', api_key)\n",
    "\n",
    "    # Step 10: Collect GDP data\n",
    "    gdp_growth_df = get_fred_data('A191RL1Q225SBEA', api_key)\n",
    "\n",
    "    # Step 11: Collect VIX data\n",
    "    vix_data = get_vix_data(start_date, end_date)\n",
    "\n",
    "    # Step 12: Collect oil prices data\n",
    "    oil_data = get_oil_prices_data(start_date, end_date)\n",
    "\n",
    "    # Step 13: Forward fill macro data\n",
    "    treasury_yield_df = forward_fill_macro_data(treasury_yield_df)\n",
    "    inflation_rate_df = forward_fill_macro_data(inflation_rate_df)\n",
    "    unemployment_rate_df = forward_fill_macro_data(unemployment_rate_df)\n",
    "    gdp_growth_df = forward_fill_macro_data(gdp_growth_df)\n",
    "    vix_data = forward_fill_macro_data(vix_data)\n",
    "    oil_data = forward_fill_macro_data(oil_data)\n",
    "\n",
    "    # Step 14: Merge macro with stock data\n",
    "    fused_data = merge_macro_with_stock(fused_data, treasury_yield_df, 'Interest_Rates')\n",
    "    fused_data = merge_macro_with_stock(fused_data, inflation_rate_df, 'Inflation_Rate')\n",
    "    fused_data = merge_macro_with_stock(fused_data, unemployment_rate_df, 'Unemployment_Rate')\n",
    "    fused_data = merge_macro_with_stock(fused_data, gdp_growth_df, 'GDP_Growth')\n",
    "    fused_data = merge_macro_with_stock(fused_data, vix_data['Close'], 'VIX')\n",
    "    fused_data = merge_macro_with_stock(fused_data, oil_data['Close'], 'Oil_Prices') \n",
    "\n",
    "    # Step 15: Calculate z-scores\n",
    "    fused_data['Z-Score'] = calculate_z_score(fused_data, window=20)\n",
    "\n",
    "    # Step 16: Calculate fibonacci levels\n",
    "    fibonacci_levels_df = calculate_fibonacci_levels(fused_data, window=100)\n",
    "    fused_data = pd.concat([fused_data, fibonacci_levels_df], axis=1)\n",
    "\n",
    "    # Step 5: Save the cleaned data\n",
    "    save_stock_data(fused_data, ticker)\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
